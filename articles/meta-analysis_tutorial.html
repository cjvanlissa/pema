<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Tutorial: Machine Learning-Informed Meta-Analysis • pema</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<script src="../extra.js"></script><meta property="og:title" content="Tutorial: Machine Learning-Informed Meta-Analysis">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">pema</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.4</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/meta-analysis_tutorial.html">Tutorial: Machine Learning-Informed Meta-Analysis</a></li>
    <li><a class="dropdown-item" href="../articles/using-brma.html">Conducting a Bayesian Regularized Meta-analysis</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/cjvanlissa/pema/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Tutorial: Machine Learning-Informed Meta-Analysis</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/cjvanlissa/pema/blob/master/vignettes/meta-analysis_tutorial.Rmd" class="external-link"><code>vignettes/meta-analysis_tutorial.Rmd</code></a></small>
      <div class="d-none name"><code>meta-analysis_tutorial.Rmd</code></div>
    </div>

    
    
<div class="section level3">
<h3 id="tutorial-requirements">Tutorial Requirements<a class="anchor" aria-label="anchor" href="#tutorial-requirements"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Install R and then RStudio
<ul>
<li>Follow the instructions here: <a href="https://posit.co/download/rstudio-desktop/" class="external-link uri">https://posit.co/download/rstudio-desktop/</a>
</li>
</ul>
</li>
<li>Open RStudio.<br>
Now, run the setup script for this workshop.<br>
In the window labeled “Console”, paste this code and press [Enter]:</li>
</ol>
<pre><code><span><span class="kw"><a href="https://rdrr.io/r/base/source.html" class="external-link">source</a></span><span class="op">(</span><span class="st">"https://raw.githubusercontent.com/cjvanlissa/meta_workshop/refs/heads/master/check_function.R"</span><span class="op">)</span></span></code></pre>
<ol start="3" style="list-style-type: decimal">
<li>If you have your own data: after running the <code><a href="https://rdrr.io/r/base/source.html" class="external-link">source()</a></code>
command above, you can use the function <code>check_data()</code>.
<ul>
<li>Load your own data into R as usual, and check if you can use it for
the workshop exercises by running:</li>
<li><code>check_data(your_data_object)</code></li>
</ul>
</li>
</ol>
</div>
<div class="section level3">
<h3 id="pool">Meta-Analysis in R<a class="anchor" aria-label="anchor" href="#pool"></a>
</h3>
<p>The essence of Meta-Analysis is <strong>pooling your effect
sizes</strong> to get an overall effect size estimate of the
studies.</p>
<p>When pooling effect sizes in Meta-Analysis, there are two basic
approaches: the <strong>Fixed-Effect-Model</strong>, or the
<strong>Random-Effects-Model</strong> <span class="citation">(Borenstein
et al. 2009)</span>. The fixed effect model assumes that one true effect
size exists in the population; the random effects model assumes that the
true effect varies (and is normally distributed).</p>
<p>Both of these models require an <strong>effect size</strong>, and a
<strong>dispersion (variance)</strong> estimate for each study.</p>
<p>For these meta-analyses, we’ll use the <code>metafor</code> package
<span class="citation">(Viechtbauer 2010)</span>. However, notice that
we load a different package, <code>metaforest</code>. The reason is that
it contains the example data for this tutorial, and it loads the
<code>metafor</code> package in turn.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">metaforest</span><span class="op">)</span></span></code></pre></div>
<div class="section level4">
<h4 id="using-your-own-data">Using Your Own Data<a class="anchor" aria-label="anchor" href="#using-your-own-data"></a>
</h4>
<p>If you want, you can conduct the examples below with your own data.
Note that the interactive questions won’t work in this case (the correct
answers are based on the <code>curry</code> data).</p>
<p>If you want to use your own data, you can use the function
<code>check_data()</code> to help make sure that your data are suitable
for the tutorial examples. Install the function by running:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/source.html" class="external-link">source</a></span><span class="op">(</span><span class="st">"https://raw.githubusercontent.com/cjvanlissa/meta_workshop/refs/heads/master/check_function.R"</span><span class="op">)</span></span></code></pre></div>
<p>Then, apply the function to your data object by running
<code>check_data(your_data_object)</code>. It will give helpful
suggestions to make it easier to follow the tutorial with your own
data:</p>
<pre><code><span><span class="co">#&gt; ✔ Looks like you're all set to do the workshop!</span></span></code></pre>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">curry</span></span>
<span><span class="fu">check_data</span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; There is no column named 'yi' in your data. If you have an effect size column, it will be easier to do the tutorial if you rename it, using syntax like this:</span></span>
<span><span class="co">#&gt;   </span></span>
<span><span class="co">#&gt;   names(df)[which(names(df) == 'youreffectsize')] &lt;- 'yi'</span></span>
<span><span class="co">#&gt;   </span></span>
<span><span class="co">#&gt;   If you do not yet have an effect size column, you may need to compute it first. Run ?metafor::escalc to see the help for this function.</span></span></code></pre>
<p>Note that the message suggests that we rename the effect size column,
which is called <code>d</code> in the <code>curry</code> dataset, to
<code>yi</code>. Let’s do that:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">==</span> <span class="st">'d'</span><span class="op">)</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">'yi'</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="using-different-demo-data">Using Different Demo Data<a class="anchor" aria-label="anchor" href="#using-different-demo-data"></a>
</h4>
<p>If you do not have your own data but are up for a challenge, you can
use a different demo dataset to complete the tutorial. Two suggestions
are:</p>
<pre><code><span><span class="fu">metaforest</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/metaforest/man/fukkink_lont.html" class="external-link">fukkink_lont</a></span></span>
<span><span class="fu">pema</span><span class="fu">::</span><span class="va"><a href="../reference/bonapersona.html">bonapersona</a></span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="fixedef">Fixed Effect Model<a class="anchor" aria-label="anchor" href="#fixedef"></a>
</h3>
<p><strong>The idea behind the fixed-effects-model</strong></p>
<p>The fixed-effects-model assumes that all observed effect sizes stem
from a single <em>true</em> population effect <span class="citation">(Borenstein et al. 2009)</span>. To calculate the
overall effect, we therefore average all effect sizes, but give studies
with greater precision a higher weight. Precision relates to the fact
that studies with a smaller <strong>Standard Error</strong> provide more
accurate estimates of the true population effect.</p>
<p>For this weighing, we use the <strong>inverse of the
variance</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>/</mi><msubsup><mover><mi>σ</mi><mo accent="true">̂</mo></mover><mi>k</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">1/\hat\sigma^2_k</annotation></semantics></math>
of each study
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>.
We then calculate a weighted average of all studies, our fixed effect
size estimator
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>F</mi></msub><annotation encoding="application/x-tex">\hat\theta_F</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>F</mi></msub><mo>=</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><mi>/</mi><msubsup><mover><mi>σ</mi><mo accent="true">̂</mo></mover><mi>k</mi><mn>2</mn></msubsup></mrow><mrow><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mn>1</mn><mi>/</mi><msubsup><mover><mi>σ</mi><mo accent="true">̂</mo></mover><mi>k</mi><mn>2</mn></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">
\begin{equation}
\hat\theta_F = \frac{\sum\limits_{k=1}^K \hat\theta_k/ \hat\sigma^2_k}{\sum\limits_{k=1}^K 1/\hat\sigma^2_k}
\end{equation}
</annotation></semantics></math></p>
<p>These examples assume you already have a dataset with the
<strong>calucated effects and SE</strong> for each study. The
<code>curry</code> data set, inside the <code>metaforest</code> package,
will do. This dataset already contains the effect sizes and their
variances, so we can directly use the <code>rma</code> function.</p>
<div class="section level4">
<h4 id="fixed-effects-model-with-rma">Fixed-effects Model with <code>rma</code><a class="anchor" aria-label="anchor" href="#fixed-effects-model-with-rma"></a>
</h4>
<p>The <code><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma()</a></code> function has many arguments, all of which you
can accessed by typing <code><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">?rma</a></code> in your console once the
<code>metafor</code> package is loaded, or selecting the function and
pressing F1.</p>
<p><strong>Here is a table with the most important arguments for our
code:</strong></p>
<table class="table">
<colgroup>
<col width="8%">
<col width="91%">
</colgroup>
<thead><tr class="header">
<th align="left">Argument</th>
<th align="left">Function</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">yi</td>
<td align="left">A vector with the effect sizes</td>
</tr>
<tr class="even">
<td align="left">vi</td>
<td align="left">A vector with the sampling variances</td>
</tr>
<tr class="odd">
<td align="left">method</td>
<td align="left">A character string, indicating what type of
meta-analysis to run. FE runs a fixed-effect model</td>
</tr>
</tbody>
</table>
<p>Let’s conduct our first fixed-effects-model Meta-Analysis. We we will
give the results of this analysis the simple name <code>m</code>.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span>yi <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">yi</span>,     <span class="co"># The yi-column of the df, which contains Cohen's d</span></span>
<span>         vi <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">vi</span>,    <span class="co"># The vi-column of the df, which contains the variances</span></span>
<span>         method <span class="op">=</span> <span class="st">"FE"</span><span class="op">)</span> <span class="co"># Run a fixed-effect model</span></span>
<span><span class="va">m</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Fixed-Effects Model (k = 56)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; I^2 (total heterogeneity / total variability):   64.95%</span></span>
<span><span class="co">#&gt; H^2 (total variability / sampling variability):  2.85</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test for Heterogeneity:</span></span>
<span><span class="co">#&gt; Q(df = 55) = 156.9109, p-val &lt; .0001</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model Results:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; estimate      se    zval    pval   ci.lb   ci.ub      </span></span>
<span><span class="co">#&gt;   0.2059  0.0219  9.4135  &lt;.0001  0.1630  0.2487  *** </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span></span></code></pre>
<p>We now see a summary of the results of our Meta-Analysis,
including</p>
<ul>
<li>The total <strong>number of included studies</strong> (k)</li>
<li>The <strong>overall effect</strong>, its confidence interval and
p-value</li>
<li>The <em>Q</em>-test of heterogeneity</li>
</ul>
<div class="webex-check webex-box">
<span>
<p style="margin-top:1em; text-align:center">
<b>Formative Assessment</b>
</p>
<p style="margin-left:1em;">
</p>
<p>How big is the overall effect?
<input class="webex-solveme nospaces" data-tol="0.01" size="5" data-answer='["0.206",".206"]'></p>
<p>True or false: A significant proportion of the variability in effect
sizes is attributable to heterogeneity, rather than sampling error.
<select class="webex-select"><option value="blank"></option>
<option value="answer">TRUE</option>
<option value="">FALSE</option></select></p>
What can you say about the heterogeneity of the population effect?
<select class="webex-select"><option value="blank"></option>
<option value="answer">It
is assumed to be zero</option>
<option value="">It is significant, Q(55)
= 156,91, p &lt; .0001</option>
<option value="">It is large, I2 =
64.95%</option>
<option value="">Can’t say anything based on this
output</option></select><p></p></span>
</div>
</div>
</div>
<div class="section level3">
<h3 id="random">Random-Effects-Model<a class="anchor" aria-label="anchor" href="#random"></a>
</h3>
<p>We can only use the fixed-effect-model when we can assume that
<strong>all included studies tap into one true effect size</strong>. In
practice this is hardly ever the case: interventions may vary in certain
characteristics, the sample used in each study might be slightly
different, or its methods. If we can assume that there are many small,
random, uncorrelated variations in true effect sizes, then a more
appropriate assumption in these cases might be that the true effect size
follows a normal distribution.</p>
<p><strong>The Idea behind the Random-Effects-Model</strong></p>
<p>In the Random-Effects-Model, we want to account for our assumption
that the population effect size is normally distributed <span class="citation">(Schwarzer, Carpenter, and Rücker 2015)</span>.</p>
<p>The fixed-effect-model assumes that when the observed effect size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><annotation encoding="application/x-tex">\hat\theta_k</annotation></semantics></math>
of an individual study
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
deviates from the true effect size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>θ</mi><mi>F</mi></msub><annotation encoding="application/x-tex">\theta_F</annotation></semantics></math>,
the only reason for this is that the estimate is burdened by (sampling)
error
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ϵ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\epsilon_k</annotation></semantics></math>.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><mo>=</mo><msub><mi>θ</mi><mi>F</mi></msub><mo>+</mo><msub><mi>ϵ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\hat\theta_k = \theta_F + \epsilon_k</annotation></semantics></math></p>
<p>While the random-effects-model assumes that, in addition, there is
<strong>a second source of error</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ζ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math>.This
second source of error is introduced by the fact that even the true
effect size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>θ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\theta_k</annotation></semantics></math>
of our study
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
is also only part of an over-arching distribution of true effect sizes
with the mean
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>μ</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math><span class="citation">(Borenstein et al. 2009)</span>.</p>
<div class="figure" style="text-align: center">
<img src="include%2Fdensity.png" alt="An illustration of  parameters of the random-effects-model" width="70%"><p class="caption">
An illustration of parameters of the random-effects-model
</p>
</div>
<p>The formula for the random-effects-model therefore looks like
this:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><mo>=</mo><mi>μ</mi><mo>+</mo><msub><mi>ϵ</mi><mi>k</mi></msub><mo>+</mo><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\hat\theta_k = \mu + \epsilon_k + \zeta_k</annotation></semantics></math></p>
<p>When calculating a random-effects-model meta-analysis, where
therefore also have to take the error
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ζ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math>
into account. To do this, we have to <strong>estimate the variance of
the distribution of true effect sizes</strong>, which is denoted by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>τ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\tau^{2}</annotation></semantics></math>,
or <em>tau<sup>2</sup></em>. There are several estimators for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>τ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\tau^{2}</annotation></semantics></math>,
all of which are implemented in <code>metafor</code>.</p>
</div>
<div class="section level3">
<h3 id="random-effects-model-with-rma">Random-Effects Model with <code>rma</code><a class="anchor" aria-label="anchor" href="#random-effects-model-with-rma"></a>
</h3>
<p>We can re-use our code from the fixed-effects-model and simply remove
the <code>method = "FE"</code> argument to conduct a random-effects
analysis with the default REML estimator for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>τ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\tau^2</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m_re</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span>yi <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">yi</span>,     <span class="co"># The yi-column of the df, which contains Cohen's d</span></span>
<span>            vi <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">vi</span><span class="op">)</span>    <span class="co"># The vi-column of the df, which contains the variances</span></span>
<span><span class="va">m_re</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random-Effects Model (k = 56; tau^2 estimator: REML)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; tau^2 (estimated amount of total heterogeneity): 0.0570 (SE = 0.0176)</span></span>
<span><span class="co">#&gt; tau (square root of estimated tau^2 value):      0.2388</span></span>
<span><span class="co">#&gt; I^2 (total heterogeneity / total variability):   67.77%</span></span>
<span><span class="co">#&gt; H^2 (total variability / sampling variability):  3.10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test for Heterogeneity:</span></span>
<span><span class="co">#&gt; Q(df = 55) = 156.9109, p-val &lt; .0001</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model Results:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; estimate      se    zval    pval   ci.lb   ci.ub      </span></span>
<span><span class="co">#&gt;   0.2393  0.0414  5.7805  &lt;.0001  0.1581  0.3204  *** </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span></span></code></pre>
<div class="webex-check webex-box">
<span>
<p style="margin-top:1em; text-align:center">
<b>Formative Assessment</b>
</p>
<p style="margin-left:1em;">
</p>
<p>How big is the overall effect?
<input class="webex-solveme nospaces" data-tol="0.01" size="4" data-answer='["0.24",".24"]'></p>
<p>What is the estimated heterogeneity?
<input class="webex-solveme nospaces" data-tol="0.01" size="4" data-answer='["0.06",".06"]'></p>
What can you say about the the expected value of the population effect
in the random-effects model, compared to the previous fixed-effect
model?
<select class="webex-select"><option value="blank"></option>
<option value="answer">It
is larger</option>
<option value="">It is
smaller</option>
<option value="">Can’t say anything based on this
output</option>
<option value="">It is about the same</option></select><p></p></span>
</div>
<p>This is caused by the fact that random-effects models assign more
equal weight to all studies, including small ones, which tend to be more
biased.</p>
</div>
<div class="section level2">
<h2 id="metareg">Meta-Regression<a class="anchor" aria-label="anchor" href="#metareg"></a>
</h2>
<p><strong>The idea behind meta-regression</strong></p>
<p>In a conventional regression, we specify a model predicting the
dependent variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>,
across
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi></mi><mi>i</mi></msub><annotation encoding="application/x-tex">_i</annotation></semantics></math>
participants, based on their values on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
predictor variables,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><mi>…</mi><msub><mi>x</mi><mrow><mi>i</mi><mi>p</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i1} \dots x_{ip}</annotation></semantics></math>.
The residual error is referred to as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ϵ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\epsilon_i</annotation></semantics></math>.
A standard regression equation therefore looks like this:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i=\beta_0 + \beta_1x_{1i} + ...+\beta_px_{pi} + \epsilon_i</annotation></semantics></math></p>
<p>In a meta-regression, we want to estimate the <strong>effect
size</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
of several studies
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi></mi><mi>k</mi></msub><annotation encoding="application/x-tex">_k</annotation></semantics></math>,
as a function of between-studies moderators. There are two sources of
heterogeneity: sampling error,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ϵ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\epsilon_k</annotation></semantics></math>,
and between-studies heterogeneity,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ζ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math>
so our regression looks like this:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>k</mi></msub><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mrow><mn>1</mn><mi>k</mi></mrow></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>k</mi></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mi>k</mi></msub><mo>+</mo><msub><mi>ζ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\theta_k = \beta_0 + \beta_1x_{1k} + ... + \beta_px_{pk} + \epsilon_k + \zeta_k</annotation></semantics></math></p>
<p>You might have seen that when estimating the effect size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>θ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\theta_k</annotation></semantics></math>
of a study
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
in our regression model, there are two <strong>extra terms in the
equation</strong>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ϵ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\epsilon_k</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ζ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math>.
The same terms can also be found in the equation for the random-effects
model. The two terms signify two types of <strong>independent
errors</strong> which cause our regression prediction to be
<strong>imperfect</strong>. The first one,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ϵ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\epsilon_k</annotation></semantics></math>,
is the sampling error through which the effect size of the study
deviates from its “true” effect. The second one,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ζ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math>,
denotes that even the true effect size of the study is only sampled from
<strong>an overarching distribution of effect sizes</strong>.</p>
<p>As the equation above has includes <strong>fixed effects</strong>
(the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
coefficients) as well as <strong>random effects</strong>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ζ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\zeta_k</annotation></semantics></math>),
the model used in meta-regression is often called <strong>a
mixed-effects-model</strong>.</p>
<div class="section level4">
<h4 id="testing-moderators-significance">Testing Moderators’ Significance<a class="anchor" aria-label="anchor" href="#testing-moderators-significance"></a>
</h4>
<p>To evaluate the <strong>statistical significance of a
predictor</strong>, we conduct a <strong>t-test</strong> (or Z-test) of
its
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>-weight.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mfrac><mi>β</mi><mrow><mi>S</mi><msub><mi>E</mi><mi>β</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex"> t=\frac{\beta}{SE_{\beta}}</annotation></semantics></math></p>
<p>Which provides a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-value
telling us if a variable significantly predicts effect size differences
in our regression model.</p>
</div>
<div class="section level4">
<h4 id="assessing-meta-regression-model-fit">Assessing Meta-Regression Model Fit<a class="anchor" aria-label="anchor" href="#assessing-meta-regression-model-fit"></a>
</h4>
<p>In conventional regression,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math>
is commonly used to quantify the percentage of variance in the data
explained by the model, as a percentage of total variance (0-100%). As
this measure is commonly used, and many researchers know how to to
interpret it, we can also calculate a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math>
analog for meta-regression using this formula:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mn>2</mn></msub><mo>=</mo><mfrac><mrow><msubsup><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mrow><mi>R</mi><mi>E</mi><mi>M</mi></mrow><mn>2</mn></msubsup><mo>−</mo><msubsup><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mrow><mi>M</mi><mi>E</mi><mi>M</mi></mrow><mn>2</mn></msubsup></mrow><msubsup><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mrow><mi>R</mi><mi>E</mi><mi>M</mi></mrow><mn>2</mn></msubsup></mfrac></mrow><annotation encoding="application/x-tex">R_2=\frac{\hat\tau^2_{REM}-\hat\tau^2_{MEM}}{\hat\tau^2_{REM}}</annotation></semantics></math></p>
<p>Where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mrow><mi>R</mi><mi>E</mi><mi>M</mi></mrow><mn>2</mn></msubsup><annotation encoding="application/x-tex">\hat\tau^2_{REM}</annotation></semantics></math>
is the estimated total heterogenetiy based on the random-effects-model
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mrow><mi>R</mi><mi>E</mi><mi>M</mi></mrow><mn>2</mn></msubsup><annotation encoding="application/x-tex">\hat\tau^2_{REM}</annotation></semantics></math>
the total heterogeneity of our mixed-effects regression model.</p>
<p>NOTE however, that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math>
refers to variance explained in the observed data. In linear regression,
the more predictors you add, the better your model will explain the
observed data. But this can decrease the generalizability of you model,
through a process called <strong>overfitting</strong>: You’re capturing
noise in your dataset, not true effects that exist in the real world. In
meta-regression, because the estimate of heterogeneity may differ, we
may not actually see the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math>
increasing with more predictors - but because the samples are often
small, be very mindful of overfitting nonetheless.</p>
</div>
<div class="section level3">
<h3 id="meta-regression-in-r">Meta-regression in R<a class="anchor" aria-label="anchor" href="#meta-regression-in-r"></a>
</h3>
<p>Meta-regressions can be conducted in R using the <code>rma</code>
function in <code>metafor</code>. First, let’s conduct a regression with
a single categorical predictor, <code>donorcode</code>, which has two
levels: <code>Anxious</code> and <code>Typical</code>:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span><span class="va">yi</span> <span class="op">~</span> <span class="va">donorcode</span>, vi <span class="op">=</span> <span class="va">vi</span>, data <span class="op">=</span> <span class="va">df</span><span class="op">)</span></span>
<span><span class="va">m_cat</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Mixed-Effects Model (k = 56; tau^2 estimator: REML)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; tau^2 (estimated amount of residual heterogeneity):     0.0567 (SE = 0.0177)</span></span>
<span><span class="co">#&gt; tau (square root of estimated tau^2 value):             0.2382</span></span>
<span><span class="co">#&gt; I^2 (residual heterogeneity / unaccounted variability): 67.81%</span></span>
<span><span class="co">#&gt; H^2 (unaccounted variability / sampling variability):   3.11</span></span>
<span><span class="co">#&gt; R^2 (amount of heterogeneity accounted for):            0.49%</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test for Residual Heterogeneity:</span></span>
<span><span class="co">#&gt; QE(df = 54) = 155.0054, p-val &lt; .0001</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test of Moderators (coefficient 2):</span></span>
<span><span class="co">#&gt; QM(df = 1) = 1.5257, p-val = 0.2168</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model Results:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                   estimate      se    zval    pval    ci.lb   ci.ub    </span></span>
<span><span class="co">#&gt; intrcpt             0.0829  0.1332  0.6222  0.5338  -0.1781  0.3439    </span></span>
<span><span class="co">#&gt; donorcodeTypical    0.1730  0.1401  1.2352  0.2168  -0.1015  0.4476    </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span></span></code></pre>
<p>By default, <code><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">metafor::rma()</a></code> will recode
<code>factor</code> variables to make one group the reference category
and create dummies for all other groups. The syntax above created a
binary indicator variable (a dummy variable) for people who fall in the
<code>Typical</code> category. It then estimated the model intercept -
which is the population effect size in the <code>Anxious</code>
category, which serves as reference category here, and the effect of the
<code>donorcodeTypical</code> dummy, which tells us the difference
between the two groups’ population effects.</p>
<div class="webex-check webex-box">
<span>
<p style="margin-top:1em; text-align:center">
<b>Formative Assessment</b>
</p>
<p style="margin-left:1em;">
</p>
<p>What is the expected population effect size in the Typical group?
<input class="webex-solveme nospaces" data-tol="0.01" size="4" data-answer='["0.17",".17"]'></p>
<p>What is the expected population effect size in the Anxious group?
<input class="webex-solveme nospaces" data-tol="0.01" size="8" data-answer='["0.255888",".255888"]'></p>
True or false: There is a significant difference between the two groups.
<select class="webex-select"><option value="blank"></option>
<option value="">TRUE</option>
<option value="answer">FALSE</option></select><p></p></span>
</div>
<div class="section level4">
<h4 id="continuous-predictors">Continuous Predictors<a class="anchor" aria-label="anchor" href="#continuous-predictors"></a>
</h4>
<p>Imagine you want to check if the <strong>proportion of male
participants</strong> is associated with effect size. The variable
<code>sex</code> contains this information. You can use this predictor
in a meta-regression:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m_reg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span><span class="va">yi</span> <span class="op">~</span><span class="va">sex</span>,</span>
<span>             vi <span class="op">=</span> <span class="va">vi</span>,</span>
<span>             data <span class="op">=</span> <span class="va">df</span><span class="op">)</span></span>
<span><span class="va">m_reg</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Mixed-Effects Model (k = 56; tau^2 estimator: REML)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; tau^2 (estimated amount of residual heterogeneity):     0.0544 (SE = 0.0173)</span></span>
<span><span class="co">#&gt; tau (square root of estimated tau^2 value):             0.2333</span></span>
<span><span class="co">#&gt; I^2 (residual heterogeneity / unaccounted variability): 66.50%</span></span>
<span><span class="co">#&gt; H^2 (unaccounted variability / sampling variability):   2.98</span></span>
<span><span class="co">#&gt; R^2 (amount of heterogeneity accounted for):            4.53%</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test for Residual Heterogeneity:</span></span>
<span><span class="co">#&gt; QE(df = 54) = 149.5878, p-val &lt; .0001</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test of Moderators (coefficient 2):</span></span>
<span><span class="co">#&gt; QM(df = 1) = 2.1607, p-val = 0.1416</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model Results:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          estimate      se    zval    pval    ci.lb   ci.ub    </span></span>
<span><span class="co">#&gt; intrcpt    0.0648  0.1253  0.5168  0.6053  -0.1808  0.3104    </span></span>
<span><span class="co">#&gt; sex        0.0050  0.0034  1.4699  0.1416  -0.0017  0.0116    </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span></span></code></pre>
<div class="webex-check webex-box">
<span>
<p style="margin-top:1em; text-align:center">
<b>Formative Assessment</b>
</p>
<p style="margin-left:1em;">
</p>
<p>True or false: There is a significant effect of sex.
<select class="webex-select"><option value="blank"></option>
<option value="">TRUE</option>
<option value="answer">FALSE</option></select></p>
How to interpret the effect of sex?
<select class="webex-select"><option value="blank"></option>
<option value="">There
is no effect of sex</option>
<option value="">The difference between men
and women is .005</option>
<option value="answer">1% increase in male
participants is associated with .005 increase of the effect
size</option>
<option value="">Can’t say based on this
output</option></select><p></p></span>
</div>
</div>
<div class="section level4">
<h4 id="multiple-meta-regression">Multiple Meta-Regression<a class="anchor" aria-label="anchor" href="#multiple-meta-regression"></a>
</h4>
<p>Previously, we only considered the scenario in which we use
<strong>one predictor</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\beta_1x_1</annotation></semantics></math>
in our meta-regression. When we add more than one predictor, we’re using
<strong>multiple meta-regression</strong>. In multiple meta-regression
we use several moderators (variables) to predict the outcome (effect
sizes). When we look back at the <strong>general
meta-regression</strong> formula we defined before, we actually see that
the formula already provides us with this feature through the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>n</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\beta_nx_{pk}</annotation></semantics></math>
part. Here, the parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
denotes that we can include
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
more predictors/variables into our meta-regression, making it a multiple
meta-regression.</p>
<p>We could include both predictors from the previous exercises in a
mutliple meta-regression as follows:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m_multi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span><span class="va">yi</span> <span class="op">~</span> <span class="va">sex</span> <span class="op">+</span> <span class="va">donorcode</span>,</span>
<span>               vi <span class="op">=</span> <span class="va">vi</span>,</span>
<span>               data <span class="op">=</span> <span class="va">df</span><span class="op">)</span></span>
<span><span class="va">m_multi</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Mixed-Effects Model (k = 56; tau^2 estimator: REML)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; tau^2 (estimated amount of residual heterogeneity):     0.0551 (SE = 0.0175)</span></span>
<span><span class="co">#&gt; tau (square root of estimated tau^2 value):             0.2347</span></span>
<span><span class="co">#&gt; I^2 (residual heterogeneity / unaccounted variability): 66.89%</span></span>
<span><span class="co">#&gt; H^2 (unaccounted variability / sampling variability):   3.02</span></span>
<span><span class="co">#&gt; R^2 (amount of heterogeneity accounted for):            3.42%</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test for Residual Heterogeneity:</span></span>
<span><span class="co">#&gt; QE(df = 53) = 148.6166, p-val &lt; .0001</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test of Moderators (coefficients 2:3):</span></span>
<span><span class="co">#&gt; QM(df = 2) = 3.0602, p-val = 0.2165</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model Results:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                   estimate      se     zval    pval    ci.lb   ci.ub    </span></span>
<span><span class="co">#&gt; intrcpt            -0.0337  0.1626  -0.2074  0.8357  -0.3523  0.2849    </span></span>
<span><span class="co">#&gt; sex                 0.0043  0.0035   1.2310  0.2183  -0.0025  0.0111    </span></span>
<span><span class="co">#&gt; donorcodeTypical    0.1361  0.1421   0.9579  0.3381  -0.1424  0.4146    </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span></span></code></pre>
<p>Now, let’s create a model that includes <em>all</em> potential
moderators of the effect size:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mods</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"sex"</span>, <span class="st">"age"</span>, <span class="st">"location"</span>, <span class="st">"donorcode"</span>, <span class="st">"interventioncode"</span>, <span class="st">"controlcode"</span>, <span class="st">"recipients"</span>, <span class="st">"outcomecode"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">res_multi2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"yi ~"</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="va">mods</span>, collapse <span class="op">=</span> <span class="st">"+"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, vi <span class="op">=</span> <span class="va">vi</span>, data <span class="op">=</span> <span class="va">df</span><span class="op">)</span></span>
<span></span>
<span><span class="va">res_multi2</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Mixed-Effects Model (k = 56; tau^2 estimator: REML)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; tau^2 (estimated amount of residual heterogeneity):     0.0038 (SE = 0.0076)</span></span>
<span><span class="co">#&gt; tau (square root of estimated tau^2 value):             0.0618</span></span>
<span><span class="co">#&gt; I^2 (residual heterogeneity / unaccounted variability): 12.55%</span></span>
<span><span class="co">#&gt; H^2 (unaccounted variability / sampling variability):   1.14</span></span>
<span><span class="co">#&gt; R^2 (amount of heterogeneity accounted for):            93.30%</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test for Residual Heterogeneity:</span></span>
<span><span class="co">#&gt; QE(df = 26) = 34.1905, p-val = 0.1303</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test of Moderators (coefficients 2:30):</span></span>
<span><span class="co">#&gt; QM(df = 29) = 105.3506, p-val &lt; .0001</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model Results:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span></span></code></pre>
<div class="webex-check webex-box">
<span>
<p style="margin-top:1em; text-align:center">
<b>Formative Assessment</b>
</p>
<p style="margin-left:1em;">
</p>
<p>What is the number of studies included in the second multiple
meta-regression (with all predictors)?
<input class="webex-solveme nospaces" data-tol="0" size="2" data-answer='["56"]'></p>
<p>What is the number of parameters of the second multiple
meta-regression (with all predictors)?
<input class="webex-solveme nospaces" data-tol="0" size="2" data-answer='["30"]'></p>
The
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math>
of the second multiple meta-regression model is 93.30%. How can we
interpret this?
<select class="webex-select"><option value="blank"></option>
<option value="answer">With
caution; the model is likely overfit.</option>
<option value="">As a
large effect; there must be several significant
moderators.</option>
<option value="">As a large effect; the moderators
explain most of the heterogeneity.</option>
<option value="">Can’t say
based on this output</option></select><p></p></span>
</div>
</div>
</div>
<div class="section level3">
<h3 id="optional-pitfalls-of-meta-regression">Optional: Pitfalls of Meta-Regression<a class="anchor" aria-label="anchor" href="#optional-pitfalls-of-meta-regression"></a>
</h3>
<p>Skip this section if you are pressed for time.</p>
<div class="section level4">
<h4 id="multicollinearity">Multicollinearity<a class="anchor" aria-label="anchor" href="#multicollinearity"></a>
</h4>
<p>When performing the analysis above, we saw a warning message:</p>
<pre><code><span><span class="co">#&gt; Warning: Redundant predictors dropped from the model.</span></span></code></pre>
<p>This warning tells us that some of the moderators conveyed exactly
the same information, and therefore, it’s not possible to include both
in the same model.</p>
<p>For example, look at the following subset of the data. Imagine that
this would be our entire dataset:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">24</span>, <span class="fl">28</span>, <span class="fl">46</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"age"</span>, <span class="st">"location"</span>, <span class="st">"interventioncode"</span>, <span class="st">"controlcode"</span>, <span class="st">"outcomecode"</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;      age location   interventioncode      controlcode outcomecode</span></span>
<span><span class="co">#&gt; 5  21.00   Canada Prosocial Spending        Self Help       Other</span></span>
<span><span class="co">#&gt; 24 20.00   Canada Prosocial Spending        Self Help   Happiness</span></span>
<span><span class="co">#&gt; 28 18.55      USA   Acts of Kindness Neutral Activity       Other</span></span>
<span><span class="co">#&gt; 46 29.95      USA   Acts of Kindness Neutral Activity       Other</span></span></code></pre></div>
<p>Note that the variable <code>age</code> has unique values for each
study, but the first two and second two studies are completely identical
in the variables <code>location</code>, <code>interventioncode</code>,
and <code>controlcode</code>. If this was our dataset, it would thus not
be possible to determine a unique effect for any of these three
variables (because they overlap completely). This is an example of
(multi)colinearity. Even more worrying: the column
<code>outcomecode</code> almost has the same value for each study. If it
did, then this column would be redundant with the model’s intercept! It
would no longer be a variable, but a constant. As it stands, only one
study is distinct in <code>outcomecode</code>. If we add a dummy for
this variable - that dummy uniquely identifies that one study (which
means the model will perfectly reproduce its value)!</p>
</div>
<div class="section level4">
<h4 id="overfitting">Overfitting<a class="anchor" aria-label="anchor" href="#overfitting"></a>
</h4>
<p>To better understand the risks of (multiple) meta-regression models,
we have to understand the concept of <strong>overfitting</strong>.
Overfitting occurs when we build a statistical model which fits the data
<strong>too closely</strong>. In essence, this means that we build a
statistical model which can predict the data at hand very well, but
performs bad at predicting future data it has never seen before. This
happens if our model assumes that some variation in our data
<strong>stems from a true “signal” in our data, when in fact we only
model random noise</strong> <span class="citation">(Hastie, Tibshirani,
and Friedman 2009)</span>. As a result, our statistical model produces
<strong>false positive results</strong>: it sees relationships where
there are none.</p>
<div class="figure">
<img src="include%2Foverfitting.png" alt="Illustration of an overfitted model vs. model with a good fit" width="70%"><p class="caption">
Illustration of an overfitted model vs. model with a good fit
</p>
</div>
<p>Regression methods, which usually utilize minimization or
maximization procedures such as Ordinary Least Squares or Maximum
Likelihood estimation, can be prone to overfitting <span class="citation">(Hastie, Tibshirani, and Friedman 2009)</span>.
Unfortunately, the risk of building a <strong>non-robust model, which
produces false-positive results</strong>, is <strong>even
higher</strong> once we go from conventional regression to
<strong>meta-regression</strong> <span class="citation">(J. P. T.
Higgins and Thompson 2004)</span>. There are several reasons for
this:</p>
<ol style="list-style-type: decimal">
<li>In Meta-Regression, our <strong>sample is often small</strong>, as
we can only use the synthesized data of all analyzed studies
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>.</li>
<li>As our meta-analysis aims to be a <strong>comprehensive overview of
all evidence</strong>, we have no <strong>additional data</strong> on
which we can “test” how well our regression model can predict high or
low effect sizes.</li>
<li>In meta-regressions, we have to deal with the potential presence of
effect size heterogeneity. Imagine a case in which we have two studies
with different effect sizes and non-overlapping confidence intervals.
Every variable which has different values for the different studies
might be a potential explanation for effect size difference we find,
while it seems straightforward that <strong>most of such explanations
are spurious</strong> <span class="citation">(J. P. T. Higgins and
Thompson 2004)</span>.</li>
<li>Meta-regression as such, and multiple meta-regression in particular,
make it very easy to <strong>“play around” with predictors</strong>. We
can test numerous meta-regression models, include many more predictors
or remove them in an attempt to explain the heterogeneity in our data.
Such an approach is of course tempting, and often found in practice,
because we, as meta-analysts, want to find a significant model which
explains why effect sizes differ <span class="citation">(J. Higgins et
al. 2002)</span>. However, such behavior <strong>massively increases the
risk of spurious findings</strong> <span class="citation">(J. P. T.
Higgins and Thompson 2004)</span>, because we can change parts of our
model indefinitely until we find a significant model, which is then very
likely to be overfitted (i.e., it mostly models statistical noise).</li>
</ol>
<p><strong>Some guidelines have been proposed to avoid an excessive
false positive rate when building meta-regression models:</strong></p>
<ul>
<li>Minimize the number of investigated predictors a priori. Predictor
selection should be based on <strong>predefined scientific or
theoretical questions</strong> we want to answer in our
meta-regression.</li>
<li>When evaluating the fit of a meta-regression model, we prefer models
which achieve a good fit with less predictors. Use fit indices that
balance fit and parsimony, such as the <em>Akaike</em> and <em>Bayesian
information criterion</em>, to determine which model to retain if you
compare several models.</li>
<li>When the number of studies is low (which is very likely to be the
case), and we want to compute the significance of a predictor, you can
use the Knapp-Hartung adjustment to obtain more reliable estimates <span class="citation">(J. Higgins et al. 2002)</span>, by specifying
<code>test = "knha</code> when calling <code><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma()</a></code>.</li>
</ul>
</div>
</div>
</div>
<div class="section level2">
<h2 id="penalized-meta-regression">Penalized Meta-Regression<a class="anchor" aria-label="anchor" href="#penalized-meta-regression"></a>
</h2>
<p>Meta-regression can be used to account for potentially relevant
between-studies differences. However, we previously saw that the number
of candidate moderators is often high relative to the number of studies.
This introduces risks of overfitting, spurious results, and model
non-convergence. Bayesian Regularized Meta-Analysis (BRMA) overcomes
these challenges, selecting relevant moderators by shrinking small
regression coefficients towards zero with regularizing (LASSO or
horseshoe) priors <span class="citation">(Van Lissa, van Erp, and
Clapper 2023)</span>. This method is suitable when there are many
potential moderators, but it is not known beforehand which of them are
relevant.</p>
<p>Let’s use Bayesian regularized meta-regression (BRMA) to select
relevant moderators!</p>
<p>First, load in the necessary packages. If you are running the model
locally on a multi-core machine, you can set
<code>options(mc.cores = 4)</code>. This runs 4 MCMC chains in parallel,
giving you multiple independent sampling chains while keeping estimation
time relatively short.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/cjvanlissa/pema" class="external-link">pema</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://cjvanlissa.github.io/tidySEM/" class="external-link">tidySEM</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>mc.cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="two-level-model">Two-level model<a class="anchor" aria-label="anchor" href="#two-level-model"></a>
</h3>
<p>First, for simplicity, we run a two-level BRMA model, ignoring the
fact that certain effect sizes come from the same study.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df_brma</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"yi"</span>, <span class="st">"vi"</span>, <span class="va">mods</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<div class="section level4">
<h4 id="two-level-model-with-the-lasso-prior">Two-level model with the lasso prior<a class="anchor" aria-label="anchor" href="#two-level-model-with-the-lasso-prior"></a>
</h4>
<p>We start with running a penalized meta-analysis using the lasso
prior. Compared to the horseshoe prior, the lasso is easier to use
because it has only two hyperparameters to set. However, the lighter
tails of the lasso can result in large coefficients being shrunken too
much towards zero thereby leading to potentially more bias compared to
the regularized horseshoe prior.</p>
<p>For the lasso prior, we need to specify the degrees of freedom
<code>df</code> and the <code>scale</code>. Both default to 1. The
degrees of freedom determines the chi-square prior that is specified for
the inverse-tuning parameter. Increasing the degrees of freedom will
allow larger values for the inverse-tuning parameter, leading to less
shrinkage. Increasing the scale parameter will also result in less
shrinkage. The influence of these hyperparameters can be visualized
through the implemented shiny app, which can be called via
<code><a href="../reference/shiny_prior.html">shiny_prior()</a></code>, and by calling
<code>plot(sample_prior())</code>.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">fit_lasso</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/brma.html">brma</a></span><span class="op">(</span><span class="va">yi</span> <span class="op">~</span> <span class="va">.</span>,</span>
<span>                  data <span class="op">=</span> <span class="va">df_brma</span>,</span>
<span>                  vi <span class="op">=</span> <span class="st">"vi"</span>,</span>
<span>                  method <span class="op">=</span> <span class="st">"lasso"</span>,</span>
<span>                  prior <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>df <span class="op">=</span> <span class="fl">1</span>, scale <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>                  mute_stan <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="section level5">
<h5 id="assessing-convergence-and-interpreting-the-results">Assessing convergence and interpreting the results<a class="anchor" aria-label="anchor" href="#assessing-convergence-and-interpreting-the-results"></a>
</h5>
<p>We can request the results using the <code>summary</code> function.
Before we interpret the results, we need to ensure that the MCMC chains
have converged to the posterior distribution. Two helpful diagnostics
provided in the summary are the number of effective posterior samples
<code>n_eff</code> and the potential scale reduction factor
<code>Rhat</code>. <code>n_eff</code> is an estimate of the number of
independent samples from the posterior. Ideally, the ratio
<code>n_eff</code> to total samples is as close to 1 as possible.
<code>Rhat</code> compares the between- and within-chain estimates and
is ideally close to 1 (indicating the chains have mixed well). Should
any values for <code>n_eff</code> or <code>Rhat</code> be far from these
ideal values, you can try increasing the number of iterations through
the <code>iter</code> argument. By default, the <code>brma</code>
function runs four MCMC chains with 2000 iterations each, half of which
is discarded as burn-in. As a result, a total of 4000 iterations is
available on which posterior summaries are based. If this does not help,
non-convergence might indicate a problem with the model
specification.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sum</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit_lasso</span><span class="op">)</span></span>
<span><span class="va">sum</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"mean"</span>, <span class="st">"sd"</span>, <span class="st">"2.5%"</span>, <span class="st">"97.5%"</span>, <span class="st">"n_eff"</span>, <span class="st">"Rhat"</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<table class="table">
<colgroup>
<col width="40%">
<col width="9%">
<col width="8%">
<col width="9%">
<col width="8%">
<col width="11%">
<col width="6%">
<col width="5%">
</colgroup>
<thead><tr class="header">
<th align="left"></th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">2.5%</th>
<th align="right">97.5%</th>
<th align="right">n_eff</th>
<th align="right">Rhat</th>
<th align="left">Sig</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Intercept</td>
<td align="right">-20.73</td>
<td align="right">14.41</td>
<td align="right">-50.96</td>
<td align="right">3.62</td>
<td align="right">1656.95</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">mTimeLength</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">-0.01</td>
<td align="right">0.00</td>
<td align="right">2070.44</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">year</td>
<td align="right">0.01</td>
<td align="right">0.01</td>
<td align="right">0.00</td>
<td align="right">0.03</td>
<td align="right">1659.60</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">modelLG</td>
<td align="right">0.09</td>
<td align="right">0.14</td>
<td align="right">-0.18</td>
<td align="right">0.40</td>
<td align="right">2283.22</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">modelLNB</td>
<td align="right">0.14</td>
<td align="right">0.11</td>
<td align="right">-0.03</td>
<td align="right">0.37</td>
<td align="right">1209.83</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">modelM</td>
<td align="right">0.02</td>
<td align="right">0.05</td>
<td align="right">-0.07</td>
<td align="right">0.13</td>
<td align="right">2208.18</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">modelMD</td>
<td align="right">0.02</td>
<td align="right">0.08</td>
<td align="right">-0.13</td>
<td align="right">0.19</td>
<td align="right">2319.51</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">ageWeek</td>
<td align="right">-0.01</td>
<td align="right">0.01</td>
<td align="right">-0.02</td>
<td align="right">0.00</td>
<td align="right">1363.64</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">strainGroupedC57Bl6</td>
<td align="right">-0.02</td>
<td align="right">0.07</td>
<td align="right">-0.16</td>
<td align="right">0.11</td>
<td align="right">2192.98</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">strainGroupedCD1</td>
<td align="right">-0.12</td>
<td align="right">0.18</td>
<td align="right">-0.53</td>
<td align="right">0.20</td>
<td align="right">2073.86</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">strainGroupedDBA</td>
<td align="right">-0.03</td>
<td align="right">0.16</td>
<td align="right">-0.36</td>
<td align="right">0.31</td>
<td align="right">1591.17</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">strainGroupedlisterHooded</td>
<td align="right">-0.05</td>
<td align="right">0.31</td>
<td align="right">-0.71</td>
<td align="right">0.54</td>
<td align="right">2062.04</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">strainGroupedlongEvans</td>
<td align="right">0.07</td>
<td align="right">0.12</td>
<td align="right">-0.14</td>
<td align="right">0.34</td>
<td align="right">2253.15</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">strainGroupedlongEvansHooded</td>
<td align="right">0.18</td>
<td align="right">0.22</td>
<td align="right">-0.18</td>
<td align="right">0.66</td>
<td align="right">2301.79</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">strainGroupedNMRI</td>
<td align="right">0.12</td>
<td align="right">0.24</td>
<td align="right">-0.33</td>
<td align="right">0.65</td>
<td align="right">2224.83</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">strainGroupedNS</td>
<td align="right">0.03</td>
<td align="right">0.15</td>
<td align="right">-0.27</td>
<td align="right">0.34</td>
<td align="right">2842.07</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">strainGroupedother</td>
<td align="right">-0.02</td>
<td align="right">0.13</td>
<td align="right">-0.28</td>
<td align="right">0.23</td>
<td align="right">2079.33</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">strainGroupedspragueDawley</td>
<td align="right">0.00</td>
<td align="right">0.06</td>
<td align="right">-0.13</td>
<td align="right">0.12</td>
<td align="right">1921.19</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">strainGroupedswissWebster</td>
<td align="right">0.56</td>
<td align="right">0.49</td>
<td align="right">-0.23</td>
<td align="right">1.64</td>
<td align="right">2230.04</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">strainGroupedwistar</td>
<td align="right">0.02</td>
<td align="right">0.06</td>
<td align="right">-0.08</td>
<td align="right">0.15</td>
<td align="right">2078.13</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">strainGroupedwistarKyoto</td>
<td align="right">0.03</td>
<td align="right">0.27</td>
<td align="right">-0.53</td>
<td align="right">0.58</td>
<td align="right">2391.66</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">bias</td>
<td align="right">-0.01</td>
<td align="right">0.03</td>
<td align="right">-0.07</td>
<td align="right">0.05</td>
<td align="right">2087.24</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">speciesrat</td>
<td align="right">0.12</td>
<td align="right">0.09</td>
<td align="right">-0.02</td>
<td align="right">0.32</td>
<td align="right">1379.54</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">domainsLearning</td>
<td align="right">0.00</td>
<td align="right">0.05</td>
<td align="right">-0.10</td>
<td align="right">0.11</td>
<td align="right">1985.97</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">domainnsLearning</td>
<td align="right">0.12</td>
<td align="right">0.08</td>
<td align="right">-0.02</td>
<td align="right">0.29</td>
<td align="right">1552.84</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">domainsocial</td>
<td align="right">0.17</td>
<td align="right">0.12</td>
<td align="right">-0.02</td>
<td align="right">0.42</td>
<td align="right">1599.73</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">domainnoMeta</td>
<td align="right">-0.36</td>
<td align="right">0.18</td>
<td align="right">-0.73</td>
<td align="right">-0.02</td>
<td align="right">1212.41</td>
<td align="right">1</td>
<td align="left">*</td>
</tr>
<tr class="even">
<td align="left">sexM</td>
<td align="right">0.12</td>
<td align="right">0.07</td>
<td align="right">0.00</td>
<td align="right">0.26</td>
<td align="right">1602.07</td>
<td align="right">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">tau2</td>
<td align="right">0.43</td>
<td align="right">0.04</td>
<td align="right">0.35</td>
<td align="right">0.51</td>
<td align="right">1112.00</td>
<td align="right">1</td>
<td align="left">*</td>
</tr>
</tbody>
</table>
<p>If we are satisfied with the convergence, we can continue looking at
the posterior summary statistics. The <code>summary</code> function
provides the posterior mean estimate for the effect of each moderator.
Since Bayesian penalization does not automatically shrink estimates
exactly to zero, some additional criterion is needed to determine which
moderators should be selected in the model. Currently, this is done
using the 95% credible intervals, with a moderator being selected if
zero is excluded in this interval. In the <code>summary</code> this is
denoted by an asterisk for that moderator.</p>
<p>Also note the summary statistics for <code>tau2</code>, the
(unexplained) residual between-studies heterogeneity.</p>
<div class="webex-check webex-box">
<span>
<p style="margin-top:1em; text-align:center">
<b>Formative Assessment</b>
</p>
<p style="margin-left:1em;">
</p>
<p>How many significant moderator effects are there?
<select class="webex-select"><option value="blank"></option>
<option value="answer">TRUE</option>
<option value="">FALSE</option></select></p>
<p>True or false: There is significant residual heterogeneity.
<select class="webex-select"><option value="blank"></option>
<option value="answer">TRUE</option>
<option value="">FALSE</option></select></p>
What can we say about the coefficients of this BRMA analysis, compared
to the previous <code><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma()</a></code> multiple regression?
<select class="webex-select"><option value="blank"></option>
<option value="answer">All
absolute BRMA coefficients are smaller than RMA
coefficients.</option>
<option value="">The BRMA coefficients are more
variable than RMA coefficients.</option>
<option value="">It is easier
for coefficients to be significant in BRMA than in
RMA.</option>
<option value="">The answer depends on the specific
analysis.</option></select><p></p></span>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="optional-three-level-model-with-horseshoe-prior">Optional: Three-level model with Horseshoe Prior<a class="anchor" aria-label="anchor" href="#optional-three-level-model-with-horseshoe-prior"></a>
</h3>
<p>The default prior in <code><a href="../reference/brma.html">brma()</a></code> is the horseshoe prior,
because it performed best in simulation studies. Moreover, we can take
into account the fact that some effect sizes might come from the same
study by fitting a three-level model as follows:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df_brma_threelevel</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"yi"</span>, <span class="st">"vi"</span>, <span class="st">"study_id"</span>, <span class="va">mods</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">7</span><span class="op">)</span></span>
<span><span class="va">fit_hs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/brma.html">brma</a></span><span class="op">(</span><span class="va">yi</span> <span class="op">~</span> <span class="va">.</span>,</span>
<span>               data <span class="op">=</span> <span class="va">df_brma_threelevel</span>,</span>
<span>               vi <span class="op">=</span> <span class="st">"vi"</span>,</span>
<span>               study <span class="op">=</span> <span class="st">"study_id"</span><span class="op">)</span></span></code></pre></div>
<div class="section level4">
<h4 id="more-information">More Information<a class="anchor" aria-label="anchor" href="#more-information"></a>
</h4>
<p><strong>Reference:</strong> <span class="citation">Van Lissa, van
Erp, and Clapper (2023)</span></p>
<p>For a more elaborate tutorial, see <a href="https://cjvanlissa.github.io/pema/articles/using-brma.html">this
vignette</a>.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="random-forest-meta-regression">Random Forest Meta-Regression<a class="anchor" aria-label="anchor" href="#random-forest-meta-regression"></a>
</h2>
<p>BRMA is comparable to multiple meta-regression, with the main
difference being that it shrinks coefficients towards zero to eliminate
irrelevant moderators. An alternative machine learning-informed approach
to moderator selection is to use tree-based methods. In this section, we
use MetaForest - a random forest-based approach - to analyze the same
data and select relevant moderators <span class="citation">(Van Lissa
2020)</span>.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load the metaforest package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">metaforest</span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: metafor</span></span>
<span><span class="co">#&gt; Loading required package: Matrix</span></span>
<span><span class="co">#&gt; Loading required package: metadat</span></span>
<span><span class="co">#&gt; Loading required package: numDeriv</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Loading the 'metafor' package (version 4.8-0). For an</span></span>
<span><span class="co">#&gt; introduction to the package please type: help(metafor)</span></span>
<span><span class="co">#&gt; Loading required package: ranger</span></span>
<span><span class="co">#&gt; Loading required package: data.table</span></span></code></pre></div>
<div class="section level4">
<h4 id="check-convergence">Check Convergence<a class="anchor" aria-label="anchor" href="#check-convergence"></a>
</h4>
<p>For any random forest model, it is important to determine how many
trees are needed to get stable results. Convergence is indicated by
stabilization of the cumulative mean squared out-of-bag prediction error
(MSEoob), as a function of the number of trees in the model. We run the
analysis once with a very high number of trees, and pick a smaller
number of trees, at which the model is also seen to have converged, to
speed up computationally heavy steps, such as replication and model
tuning. We re-examine convergence for the final model. Note that we can
account for multiple effect sizes per study in <code>MetaForest</code>
as well:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Run model with many trees to check convergence</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">74</span><span class="op">)</span></span>
<span><span class="va">check_conv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/metaforest/man/MetaForest.html" class="external-link">MetaForest</a></span><span class="op">(</span><span class="va">yi</span><span class="op">~</span><span class="va">.</span>,</span>
<span>data <span class="op">=</span> <span class="va">df_brma_threelevel</span>,</span>
<span>study <span class="op">=</span> <span class="st">"study_id"</span>,</span>
<span>whichweights <span class="op">=</span> <span class="st">"random"</span>,</span>
<span>num.trees <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="co"># Plot convergence trajectory</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">check_conv</span><span class="op">)</span></span></code></pre></div>
<p><img src="check_conv.png" width="70%"></p>
<p>This model converges at around 2500 trees.</p>
</div>
<div class="section level4">
<h4 id="model-tuning">Model Tuning<a class="anchor" aria-label="anchor" href="#model-tuning"></a>
</h4>
<p>Machine learning models often have hyperparameters that must be tuned
to get good performance for a specific learning task. We can tune the
model using the R package <code>caret</code>. As tuning parameters, we
consider all three types of weights (uniform, fixed-, and
random-effects), the number of candidate variables at each split from
2–6, and a minimum node size from 2–6. We select the model with smallest
root mean squared prediction error (RMSE) as the final model, based on
5-fold clustered cross-validation. Clustered cross-validation means that
effect sizes from the same study are always included in the same fold,
to account for the dependency in the data. Note that the number of folds
cannot exceed the number of clusters in the data. Moreover, if the
number of clusters is very small, one might have to resort to specifying
the same number of folds as clusters. Model tuning is computationally
intensive and might take a long time.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load caret</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/" class="external-link">caret</a></span><span class="op">)</span></span>
<span><span class="co"># Set up 5-fold clustered CV</span></span>
<span><span class="va">grouped_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/trainControl.html" class="external-link">trainControl</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"cv"</span>,</span>
<span>index <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/createDataPartition.html" class="external-link">groupKFold</a></span><span class="op">(</span><span class="va">df_brma_threelevel</span><span class="op">$</span><span class="va">study_id</span>, k <span class="op">=</span> <span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set up a tuning grid</span></span>
<span><span class="va">tuning_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>whichweights <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"random"</span>, <span class="st">"fixed"</span>, <span class="st">"unif"</span><span class="op">)</span>,</span>
<span>mtry <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">6</span>,</span>
<span>min.node.size <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span></span>
<span><span class="co"># X should contain only retained moderators, clustering variable, and vi</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="va">df_brma_threelevel</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"study_id"</span>, <span class="st">"vi"</span>, <span class="va">mods</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co"># Train the model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">mf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/train.html" class="external-link">train</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">df_brma_threelevel</span><span class="op">$</span><span class="va">yi</span>,</span>
<span>x <span class="op">=</span> <span class="va">X</span>,</span>
<span>study <span class="op">=</span> <span class="st">"study_id"</span>, <span class="co"># Name of the clustering variable</span></span>
<span>method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/metaforest/man/ModelInfo_mf.html" class="external-link">ModelInfo_mf</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>trControl <span class="op">=</span> <span class="va">grouped_cv</span>,</span>
<span>tuneGrid <span class="op">=</span> <span class="va">tuning_grid</span>,</span>
<span>num.trees <span class="op">=</span> <span class="fl">2500</span><span class="op">)</span></span>
<span><span class="co"># Best model tuning parameters</span></span>
<span><span class="va">mf_cv</span><span class="op">$</span><span class="va">results</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">mf_cv</span><span class="op">$</span><span class="va">results</span><span class="op">$</span><span class="va">RMSE</span><span class="op">)</span>, <span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;    whichweights mtry min.node.size      RMSE  Rsquared       MAE     RMSESD</span></span>
<span><span class="co">#&gt; 32        fixed    3             3 0.2760904 0.2936028 0.2240218 0.08613236</span></span>
<span><span class="co">#&gt;    RsquaredSD      MAESD</span></span>
<span><span class="co">#&gt; 32  0.2951682 0.06719638</span></span></code></pre>
<p>Based on the root mean squared error, the best combination of tuning
parameters were fixed-effect weights, with three candidate variables per
split, and a minimum of three cases per terminal node.</p>
</div>
<div class="section level4">
<h4 id="interpreting-the-results">Interpreting the Results<a class="anchor" aria-label="anchor" href="#interpreting-the-results"></a>
</h4>
<p>The object returned by train already contains the final model,
estimated with the best combination of tuning parameters.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract final model</span></span>
<span><span class="va">final</span> <span class="op">&lt;-</span> <span class="va">mf_cv</span><span class="op">$</span><span class="va">finalModel</span></span>
<span><span class="co"># Extract R^2_oob from the final model</span></span>
<span><span class="va">r2_oob</span> <span class="op">&lt;-</span> <span class="va">final</span><span class="op">$</span><span class="va">forest</span><span class="op">$</span><span class="va">r.squared</span></span></code></pre></div>
<p>This model has a positive estimate of explained variance in new data,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>R</mi><mrow><mi>o</mi><mi>o</mi><mi>b</mi></mrow><mn>2</mn></msubsup><mo>=</mo><mn>.19</mn></mrow><annotation encoding="application/x-tex">R^2_{oob} = .19</annotation></semantics></math>.</p>
<p>Now, we proceed to interpreting the moderator effects, by examining
variable importance and partial dependence plots. Variable importance is
determined by randomly permuting each variable in turn (so it loses all
meaningful association with the outcome), and then assessing how much
the model’s predictive performance diminishes after this random
permutation. For an important variable, the model performance drops
after permutation. Partial dependence plots show the model’s predicted
values at different levels of one variable, averaging over the values of
all other variables. Thus, you can think of this as the bivariate
marginal association.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plot variable importance</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/metaforest/man/VarImpPlot.html" class="external-link">VarImpPlot</a></span><span class="op">(</span><span class="va">final</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Sort the variable names by importance</span></span>
<span><span class="va">ordered_vars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">final</span><span class="op">$</span><span class="va">forest</span><span class="op">$</span><span class="va">variable.importance</span><span class="op">)</span><span class="op">[</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">final</span><span class="op">$</span><span class="va">forest</span><span class="op">$</span><span class="va">variable.importance</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Plot partial dependence</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/metaforest/man/PartialDependence.html" class="external-link">PartialDependence</a></span><span class="op">(</span><span class="va">final</span>, vars <span class="op">=</span> <span class="va">ordered_vars</span>,</span>
<span>rawdata <span class="op">=</span> <span class="cn">TRUE</span>, pi <span class="op">=</span> <span class="fl">.95</span><span class="op">)</span></span></code></pre></div>
<div class="webex-check webex-box">
<span>
<p style="margin-top:1em; text-align:center">
<b>Formative Assessment</b>
</p>
<p style="margin-left:1em;">
</p>
<p>What does the negative permutation importance for
<code>donorcode</code> indicate?
<select class="webex-select"><option value="blank"></option>
<option value="">Prosocial
Spending</option>
<option value="">Other</option>
<option value="answer">Acts
of Kindness</option></select></p>
<p>Which intervention has the lowest associated effect size?
<select class="webex-select"><option value="blank"></option>
<option value="answer">Randomly
permuting this variable improves model fit</option>
<option value="">This
variable has a positive effect on the outcome (effect
size)</option>
<option value="">Randomly permuting this variable
diminishes model fit</option>
<option value="">This variable has a
negative effect on the outcome (effect size)</option></select></p>
Which variable has apparent outlier(s)?
<select class="webex-select"><option value="blank"></option>
<option value="">donorcode</option>
<option value="">outcomecode</option>
<option value="answer">age</option></select><p></p></span>
</div>
</div>
<div class="section level4">
<h4 id="more-information-1">More Information<a class="anchor" aria-label="anchor" href="#more-information-1"></a>
</h4>
<p><strong>Reference:</strong> <span class="citation">Van Lissa
(2020)</span></p>
<p>For a more elaborate tutorial, see <a href="https://doi.org/10.4324/9780429273872-16" class="external-link">this open access book
chapter on MetaForest</a>.</p>
</div>
</div>
<div class="section level2">
<h2 id="bayesian-evidence-synthesis">Bayesian Evidence Synthesis<a class="anchor" aria-label="anchor" href="#bayesian-evidence-synthesis"></a>
</h2>
<p>Heterogeneity presents a fundamental challenge to research synthesis
methods <span class="citation">(J. P. T. Higgins, Thompson, and
Spiegelhalter 2009)</span>. When studies all assess the same informative
hypothesis, but differ in fundamental ways that preclude aggregation
through conventional meta-analysis methods, Bayesian Evidence Synthesis
(BES) can be used. Consider, for example, the situation that arises when
the number of moderators is very large relative to the number of
studies, or when moderators are redundant (see Meta-Regression chapter
above).</p>
<p>The PBF <span class="citation">(Van Lissa, Kuiper, and Clapper
2023)</span> can be used instead of random-effects meta-analysis when
its assumptions were likely to be violated. This Tutorial illustrates
the use of the PBF in such cases.</p>
<p>At the start of the day, we conducted random- and fixed effects
meta-analyses using the function <code><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma()</a></code> from the
<code>metafor</code> package. This required the <code>yi</code> and
<code>vi</code> columns. Now, we will perform a PBF analysis using the
<code><a href="https://rdrr.io/pkg/bain/man/pbf.html" class="external-link">pbf()</a></code> function in the <code>bain</code> package, which
accepts the same arguments.</p>
<p>First, we will load the required packages.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://informative-hypotheses.sites.uu.nl/software/bain/" class="external-link">bain</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level4">
<h4 id="repeating-the-rma">Repeating the RMA<a class="anchor" aria-label="anchor" href="#repeating-the-rma"></a>
</h4>
<p>Let’s repeat our previous random effects meta-analysis, and examine a
funnel plot of the distribution of effect sizes:</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res_rma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span>yi <span class="op">=</span> <span class="va">yi</span>, vi <span class="op">=</span> <span class="va">vi</span>, data <span class="op">=</span> <span class="va">df</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://wviechtb.github.io/metafor/reference/funnel.html" class="external-link">funnel</a></span><span class="op">(</span><span class="va">res_rma</span><span class="op">)</span></span></code></pre></div>
<p><img src="meta-analysis_tutorial_files/figure-html/unnamed-chunk-50-1.png" width="700"></p>
<p>An effect size over 0 means that helping others increased happiness,
even a little bit.</p>
<p>With a Bayes Factor, we could test the informative hypothesis (just a
directional null hypothesis) that helping increases happiness in one
particular study, for example the first row of the dataset:</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/bain/man/bain.html" class="external-link">bain</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"yi"</span> <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">yi</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>, <span class="co"># Select the first effect size</span></span>
<span>     Sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">vi</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, <span class="co"># Make covariance matrix</span></span>
<span>     hypothesis <span class="op">=</span> <span class="st">"yi &gt; 0"</span>, <span class="co"># Define informative hypothesis</span></span>
<span>     n <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">n1i</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">+</span><span class="va">df</span><span class="op">$</span><span class="va">n2c</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="co"># Calculate total sample size</span></span>
<span><span class="co">#&gt; Bayesian informative hypothesis testing for an object of class numeric:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;    Fit   Com   BF.u  BF.c     PMPa  PMPb  PMPc </span></span>
<span><span class="co">#&gt; H1 0.999 0.500 1.999 1508.434 1.000 0.667 0.999</span></span>
<span><span class="co">#&gt; Hu                                  0.333      </span></span>
<span><span class="co">#&gt; Hc 0.001 0.500 0.001                      0.001</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Hypotheses:</span></span>
<span><span class="co">#&gt;   H1: yi&gt;0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Note: BF.u denotes the Bayes factor of the hypothesis at hand versus the unconstrained hypothesis Hu. BF.c denotes the Bayes factor of the hypothesis at hand versus its complement. PMPa contains the posterior model probabilities of the hypotheses specified. PMPb adds Hu, the unconstrained hypothesis. PMPc adds Hc, the complement of the union of the hypotheses specified.</span></span></code></pre></div>
<p>The results indicate that the first study provides 1508 times more
evidence <em>in favor</em> of our informative hypothesis (helping
increases happiness) than against it,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>F</mi><mo>=</mo><mn>1508.434</mn></mrow><annotation encoding="application/x-tex">BF = 1508.434</annotation></semantics></math>.</p>
</div>
<div class="section level4">
<h4 id="product-bayes-factor">Product Bayes Factor<a class="anchor" aria-label="anchor" href="#product-bayes-factor"></a>
</h4>
<p>We now perform the PBF analysis, using the <code><a href="https://rdrr.io/pkg/bain/man/pbf.html" class="external-link">pbf()</a></code> method
for numeric input (see <code><a href="https://rdrr.io/pkg/bain/man/pbf.html" class="external-link">?pbf</a></code>). This interface is very
similar to <code><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma()</a></code>, and is specifically designed for
applications where PBF is applied to meta-analytic datasets. The
<code>yi</code> and <code>vi</code> arguments are the same as those of
<code><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma()</a></code>. Additional argument <code>ni</code> is used to
construct the prior for the approximate Bayes factors <span class="citation">(Hoijtink et al. 2019)</span>. Importantly, the
<code>hypothesis</code> argument determines which informative hypotheses
are tested.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">res_pbf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/bain/man/pbf.html" class="external-link">pbf</a></span><span class="op">(</span>yi <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">yi</span>,</span>
<span>               vi <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">vi</span>,</span>
<span>               ni <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">n1i</span><span class="op">+</span><span class="va">df</span><span class="op">$</span><span class="va">n2c</span><span class="op">)</span>,</span>
<span>               hypothesis <span class="op">=</span> <span class="st">"y &gt; 0"</span><span class="op">)</span></span></code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="right">PBF</th>
<th align="right">Sample.1</th>
<th align="right">Sample.2</th>
<th align="right">Sample.3</th>
</tr></thead>
<tbody><tr class="odd">
<td align="left">H1: y&gt;0</td>
<td align="right">7.449242e+69</td>
<td align="right">1508.434</td>
<td align="right">4.579145</td>
<td align="right">81.31709</td>
</tr></tbody>
</table>
<p>The resulting output shows the product Bayes factors for our
informative hypothesis (PBF column), as well as study-specific Bayes
factors (remaining columns, trimmed here to keep the document tidy). The
PBF in favor of our hypothesis is very high (a 7.45 with 69 zeroes), so
the body of evidence provides consistent support for the notion that
helping increases happiness.</p>
<div class="webex-check webex-box">
<span>
<p style="margin-top:1em; text-align:center">
<b>Formative Assessment</b>
</p>
<p style="margin-left:1em;">
</p>
<p>What does a negative Bayes factor indicate, for a Bayes factor
comparing an informative hypothesis Hi against its complement Hc?
<select class="webex-select"><option value="blank"></option>
<option value="answer">Negative
Bayes factors don’t exist</option>
<option value="">The evidence for Hc
outweighs the evidence for Hi</option>
<option value="">The evidence for
Hi outweighs the evidence for Hc</option>
<option value="">The evidence
for Hi outweighs the evidence for Hc, but the effect is
negative</option></select></p>
<p>True or false: All Bayes factors must exceed one (BF &gt; 1) to
obtain a PBF that also exceeds one (PBF &gt; 1)
<select class="webex-select"><option value="blank"></option>
<option value="">TRUE</option>
<option value="answer">FALSE</option></select></p>
True or false: A large Bayes factor means that the hypothesized effect
likely exists in the population
<select class="webex-select"><option value="blank"></option>
<option value="">TRUE</option>
<option value="answer">FALSE</option></select><p></p></span>
</div>
<p>This last question relates to generalizability. When we perform a
normal fixed- or random-effects meta-analysis, we rely on sampling
theory and assume that each effect size represents a random sample from
the population of possible effect sizes.</p>
<p>If this assumption is justified, then we can claim that the pooled
effect size generalized to the population those effect sizes were
randomly sampled from. Thus, our pooled effect size tells us something
about future studies.</p>
<p>Of course, this assumption is very questionable, due to publication
bias, and the fact that researchers build upon previous work! So in
practice, meta-analysis might not be as generalizable as we’d like.</p>
<p>The PBF does not rely on sampling theory and does not make such
assumptions about random sampling from the population. As a result, it
can only be interpreted as a quantitative summary of the evidence
<em>within the present sample of studies</em>.</p>
<p>It would be incorrect to interpret the PBF as saying anything about
the population; we should interpret it as a summary statistic of the
studies at hand. Of course, the same could be said about conventional
meta-analysis, if the assumption of random sampling is violated.</p>
</div>
<div class="section level4">
<h4 id="more-information-2">More Information<a class="anchor" aria-label="anchor" href="#more-information-2"></a>
</h4>
<p><strong>References:</strong> <span class="citation">Van Lissa,
Kuiper, and Clapper (2023)</span>, <span class="citation">Van Lissa et
al. (2020)</span></p>
<p>For a more elaborate tutorial on the Product Bayes Factor, see <a href="https://osf.io/preprints/psyarxiv/nvqpw" class="external-link">this paper, in press at
Research Synthesis Methods</a>.</p>
</div>
<div class="section level3">
<h3 id="credit">Credit<a class="anchor" aria-label="anchor" href="#credit"></a>
</h3>
<p>This tutorial is partly based on the book <em>Doing Meta-Analysis
with R: A Hands-On Guide</em>, which is also recommended as further
reading:</p>
<blockquote>
<p>Harrer, M., Cuijpers, P., Furukawa, T.A., &amp; Ebert, D.D. (2021).
<em>Doing Meta-Analysis with R: A Hands-On Guide</em>. Boca Raton, FL
and London: Chapmann &amp; Hall/CRC Press. ISBN 978-0-367-61007-4.</p>
</blockquote>
</div>
<div class="section level3">
<h3 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-borensteinIntroductionMetaAnalysis2009" class="csl-entry">
Borenstein, Michael, Larry V. Hedges, Julian P. T. Higgins, and Hannah
R. Rothstein. 2009. <em>Introduction to <span>Meta-Analysis</span></em>.
John Wiley &amp; Sons, Ltd. <a href="https://doi.org/10.1002/9780470743386" class="external-link">https://doi.org/10.1002/9780470743386</a>.
</div>
<div id="ref-hastieElementsStatisticalLearning2009" class="csl-entry">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The
Elements of Statistical Learning: <span>Data</span> Mining, Inference,
and Prediction</em>. Second. New York: Springer.
</div>
<div id="ref-higginsControllingRiskSpurious2004" class="csl-entry">
Higgins, Julian P. T., and Simon G. Thompson. 2004. <span>“Controlling
the Risk of Spurious Findings from Meta-Regression.”</span>
<em>Statistics in Medicine</em> 23 (11): 1663–82. <a href="https://doi.org/10.1002/sim.1752" class="external-link">https://doi.org/10.1002/sim.1752</a>.
</div>
<div id="ref-higginsReevaluationRandomeffectsMetaanalysis2009" class="csl-entry">
Higgins, Julian P. T., Simon G. Thompson, and David J Spiegelhalter.
2009. <span>“A Re-Evaluation of Random-Effects Meta-Analysis.”</span>
<em>Journal of the Royal Statistical Society. Series A, (Statistics in
Society)</em> 172 (1): 137–59. <a href="https://doi.org/10.1111/j.1467-985X.2008.00552.x" class="external-link">https://doi.org/10.1111/j.1467-985X.2008.00552.x</a>.
</div>
<div id="ref-higginsStatisticalHeterogeneitySystematic2002" class="csl-entry">
Higgins, Julian, Simon Thompson, Jonathan Deeks, and Douglas Altman.
2002. <span>“Statistical Heterogeneity in Systematic Reviews of Clinical
Trials: A Critical Appraisal of Guidelines and Practice.”</span>
<em>Journal of Health Services Research &amp; Policy</em> 7 (1): 51–61.
<a href="https://doi.org/10.1258/1355819021927674" class="external-link">https://doi.org/10.1258/1355819021927674</a>.
</div>
<div id="ref-hoijtinkTutorialTestingHypotheses2019" class="csl-entry">
Hoijtink, Herbert, Joris Mulder, Caspar van Lissa, and Xin Gu. 2019.
<span>“A Tutorial on Testing Hypotheses Using the <span>Bayes</span>
Factor.”</span> <em>Psychological Methods</em> 24 (5): 539–56. <a href="https://doi.org/10.1037/met0000201" class="external-link">https://doi.org/10.1037/met0000201</a>.
</div>
<div id="ref-schwarzerMetaAnalysis2015" class="csl-entry">
Schwarzer, Guido, James R. Carpenter, and Gerta Rücker. 2015.
<em>Meta-<span>Analysis</span> with <span>R</span></em>. Use
<span>R</span>! Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-21416-0" class="external-link">https://doi.org/10.1007/978-3-319-21416-0</a>.
</div>
<div id="ref-vanlissaSmallSampleMetaanalyses2020" class="csl-entry">
Van Lissa, Caspar J. 2020. <span>“Small Sample Meta-Analyses:
<span>Exploring</span> Heterogeneity Using
<span>MetaForest</span>.”</span> In <em>Small <span>Sample Size
Solutions</span> (<span>Open Access</span>): <span>A Guide</span> for
<span>Applied Researchers</span> and <span>Practitioners</span></em>,
edited by Rens Van De Schoot and Milica Miočević. European
<span>Association</span> of <span>Methodology Series</span>. CRC Press.
</div>
<div id="ref-vanlissaSelectingRelevantModerators2023a" class="csl-entry">
Van Lissa, Caspar J., Sara van Erp, and Eli-Boaz Clapper. 2023.
<span>“Selecting Relevant Moderators with <span>Bayesian</span>
Regularized Meta-Regression.”</span> <em>Research Synthesis Methods</em>
14 (2): 301–22. <a href="https://doi.org/10.1002/jrsm.1628" class="external-link">https://doi.org/10.1002/jrsm.1628</a>.
</div>
<div id="ref-vanlissaTeacherCornerEvaluating2020" class="csl-entry">
Van Lissa, Caspar J., Xin Gu, Joris Mulder, Yves Rosseel, Camiel Van
Zundert, and Herbert Hoijtink. 2020. <span>“Teacher’s
<span>Corner</span>: <span>Evaluating Informative Hypotheses
Using</span> the <span>Bayes Factor</span> in <span>Structural Equation
Models</span>.”</span> <em>Structural Equation Modeling: A
Multidisciplinary Journal</em> 0 (0): 1–10. <a href="https://doi.org/10.1080/10705511.2020.1745644" class="external-link">https://doi.org/10.1080/10705511.2020.1745644</a>.
</div>
<div id="ref-vanlissaAggregatingEvidenceConceptual2023" class="csl-entry">
Van Lissa, Caspar J., Rebecca M. Kuiper, and Eli-Boaz Clapper. 2023.
<span>“Aggregating Evidence from Conceptual Replication Studies Using
the Product <span>Bayes</span> Factor.”</span> Preprint. PsyArXiv. <a href="https://doi.org/10.31234/osf.io/nvqpw" class="external-link">https://doi.org/10.31234/osf.io/nvqpw</a>.
</div>
<div id="ref-viechtbauerConductingMetaanalysesMetafor2010" class="csl-entry">
Viechtbauer, Wolfgang. 2010. <span>“Conducting Meta-Analyses in
<span>R</span> with the Metafor Package.”</span> <em>Journal of
Statistical Software</em> 36 (3): 1–48.
</div>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Caspar J van Lissa, Sara J van Erp.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
